{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c98a266",
   "metadata": {},
   "source": [
    "Now, let me show the steps to follow to avoid finding a \"lucky\"\n",
    "strategy or an overfitted strategy like in our previous example:\n",
    "1. Find the data, create new features, and split the dataset.\n",
    "2. Create a strategy and OPTIMIZE it on the train set\n",
    "3. Backtest the strategy on the test set: keep it if it is good or stop\n",
    "here. Do not change the strategy's parameters; the strategy is not\n",
    "profitable. It does not matter; we will try another one!\n",
    "We need to understand that the more we touch our test set to adapt the\n",
    "strategy, the more we will have bad performances in the future (in live\n",
    "trading).\n",
    "\n",
    "The second rule to follow when we backtest a\n",
    "strategy is not to consider the big profit.\n",
    "\n",
    "Always adapt the analysis of your backtest to your\n",
    "target strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13887251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_timestamp_extremum (data , df_lowest_timeframe): \n",
    "    \"\"\" \n",
    "    :params: data(highest timeframe OHLCV data), df_lowest_timeframe (lowest timeframe OHLCV data) \n",
    "    :return: data with three new columns: Low_time (TimeStamp), High_time (TimeStamp), High_first (Boolean) \n",
    "    \"\"\"\n",
    "    \n",
    "    # Set new columns\n",
    "    data[ \"Low_time\" ] = np.nan \n",
    "    data[ \"High_time\" ] = np.nan \n",
    "    data[ \"First\" ] = np.nan\n",
    "    \n",
    "    # Loop to find out which of the Take Profit and Stop loss appears first\n",
    "    for i in tqdm( range ( len (data) - 1 )):\n",
    "        \n",
    "        # Extract values from the lowest timeframe dataframe\n",
    "        start = data.iloc[i:i + 1 ].index[ 0 ] \n",
    "        end = data.iloc[i + 1 :i + 2 ].index[ 0 ] \n",
    "        row_lowest_timeframe = df_lowest_timeframe.loc[start:end]. iloc[: -1 ]\n",
    "        \n",
    "        # Extract Timestamp of the max and min over the period (highest timeframe)\n",
    "        try : \n",
    "            high = row_lowest_timeframe[ \"high\" ].idxmax() \n",
    "            low = row_lowest_timeframe[ \"low\" ].idxmin() \n",
    "            data.loc[start, \"Low_time\" ] = low \n",
    "            data.loc[start, \"High_time\" ] = high \n",
    "        except Exception as e: \n",
    "            print (e) \n",
    "            data.loc[start, \"Low_time\" ] = start \n",
    "            data.loc[start, \"High_time\" ] = start\n",
    "            \n",
    "    # Find out which appears first\n",
    "    data.loc[data[ \"High_time\" ] > data[ \"Low_time\" ], \"First\" ] = 1 \n",
    "    data.loc[data[ \"High_time\" ] < data[ \"Low_time\" ], \"First\" ] = 2 \n",
    "    data.loc[data[ \"High_time\" ] == data[ \"Low_time\" ], \"First\" ] = 0\n",
    "        \n",
    "    # Verify the number of row without both TP and SL on same time\n",
    "    percentage_garbage_row= len (data.loc[data[ \"First\" ]== 0 ].dropna()) / len (data) * 100 \n",
    "\n",
    "    #if percentage_garbage_row<95: \n",
    "    print ( f \"WARNINGS: Garbage row: { '%.2f' % percentage_garbage_row} %\" )\n",
    "\n",
    "    # Transform the columns in datetime columns\n",
    "    data.High_time = pd.to_datetime(data.High_time) \n",
    "    data.Low_time = pd.to_datetime(data.Low_time)\n",
    "\n",
    "    # We delete the last row because we can't find the extremum\n",
    "    data = data.iloc[: -1 ]\n",
    "\n",
    "    # Specific to the current data\n",
    "    if \"timestamp\" is data.columns: \n",
    "        del data[ \"timestamp\" ] \n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46590847",
   "metadata": {},
   "source": [
    "It will be very simple. To compute the returns using a Take-profit /\n",
    "Stop-loss exit strategy, we need to consider four cases:\n",
    "1. We open a buy position, and we touch the TP first (High price)\n",
    "2. We open a buy position, and we touch the SL first (Low price)\n",
    "3. We open a sell position, and we touch the TP first (Low price)\n",
    "4. We open a sell position, and we touch the SL first (High price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f5eb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random signals\n",
    "np.random.seed( 70 ) \n",
    "values = [ -1 , 0 , 1 ] \n",
    "df[ \"Signal\" ] = [np.random.choice(values , p=[ 0.10 , 0.80 , 0.10 ]) for _ in range ( len (df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ee51ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tp_sl ( data , leverage = 1 , tp = 0.015 , sl = -0.015 , cost = 0.00 ): \n",
    "    \"\"\" \n",
    "        :params (mandatory): data(have to contain a High_time and a Low_time columns) \n",
    "        :params (optional): leverage=1, tp=0.015, sl=-0.015, cost=0.00 \n",
    "        :return: data with three new columns: Low_time (TimeStamp), High_time (TimeStamp), High_first (Boolean) \n",
    "    \"\"\"\n",
    "\n",
    "    # Set some parameters\n",
    "    buy= False sell= False data[ \"duration\" ] = 0 \n",
    "    \n",
    "    for i in range ( len (data)):\n",
    "\n",
    "        # Extract data\n",
    "        row = data.iloc[i] \n",
    "\n",
    "        ######## OPEN BUY ######## \n",
    "        if buy== False and row[ \"Signal\" ]== 1 : \n",
    "            buy = True \n",
    "            open_buy_price = row[ \"open\" ] \n",
    "            open_buy_date = row.name \n",
    "            \n",
    "        #VERIF \n",
    "        if buy: \n",
    "            var_buy_high = (row[ \"high\" ] - open_buy_price) / open_buy_price \n",
    "            var_buy_low = (row[ \"low\" ] - open_buy_price) / open_buy_price\n",
    "\n",
    "        # VERIF FOR TP AND SL ON THE SAME CANDLE \n",
    "        if (var_buy_high > tp) and (var_buy_low < sl):\n",
    "\n",
    "            # IF TP / SL ON THE SAME TIMESTAMP, WE DELETE THE TRADE RETURN \n",
    "            if row[ \"Low_time\" ] == row[ \"High_time\" ]: \n",
    "                pass \n",
    "            elif row[ \"First\" ]== 2 : \n",
    "                data.loc[row.name, \"returns\" ] = (tp-cost) * leverage \n",
    "                data.loc[row.name, \"duration\" ] = row.High_time – open_buy_date \n",
    "            elif row[ \"First\" ]== 1 : \n",
    "                data.loc[row.name, \"returns\" ] = (sl-cost) * leverage \n",
    "                data.loc[row.name, \"duration\" ] = row.Low_time – open_buy_date \n",
    "                \n",
    "                buy = False \n",
    "                open_buy_price = None \n",
    "                var_buy_high = 0 \n",
    "                var_buy_low = 0 \n",
    "                open_buy_date = None \n",
    "                \n",
    "            elif var_buy_high > tp: \n",
    "                data.loc[row.name, \"returns\" ] = (tp-cost) * leverage \n",
    "                buy = False \n",
    "                open_buy_price = None \n",
    "                var_buy_high = 0 \n",
    "                var_buy_low = 0 \n",
    "                data.loc[row.name, \"duration\" ] = row.High_time – open_buy_date \n",
    "                open_buy_date = None \n",
    "                \n",
    "            elif var_buy_low < sl: \n",
    "                data.loc[row.name, \"returns\" ] = (sl-cost) * leverage \n",
    "                buy = False \n",
    "                open_buy_price = None \n",
    "                var_buy_high = 0 \n",
    "                var_buy_low = 0 \n",
    "                data.loc[row.name, \"duration\" ] = row.Low_time – open_buy_date \n",
    "                open_buy_date = None \n",
    "                \n",
    "            ######## OPEN SELL ######## \n",
    "            if sell== False and row[ \"Signal\" ]== -1 : \n",
    "                sell = True \n",
    "                open_sell_price = row[ \"open\" ] \n",
    "                open_sell_date = row.name \n",
    "            # VERIF \n",
    "            if sell: \n",
    "                var_sell_high = -(row[ \"high\" ] - open_sell_price) / open_sell_price \n",
    "                var_sell_low = -(row[ \"low\" ] - open_sell_price) / open_sell_price \n",
    "                \n",
    "                if (var_sell_low > tp) and (var_sell_high < sl): \n",
    "                    if row[ \"Low_time\" ] == row[ \"High_time\" ]: \n",
    "                        pass \n",
    "                    elif row[ \"First\" ]== 1 : #À INVERSER POUR LE BUY \n",
    "                        data.loc[row.name, \"returns\" ] = (tp-cost) * leverage \n",
    "                        data.loc[row.name, \"duration\" ] = row.Low_time – open_sell_date \n",
    "                    elif row[ \"First\" ]== 2 : \n",
    "                        data.loc[row.name, \"returns\" ] = (sl-cost) * leverage \n",
    "                        data.loc[row.name, \"duration\" ] = row.High_time – open_sell_date \n",
    "                        sell = False \n",
    "                        open_sell_price = None \n",
    "                        var_sell_high = 0 \n",
    "                        var_sell_low = 0 \n",
    "                        open_sell_date = None \n",
    "                    \n",
    "                    elif var_sell_low > tp: \n",
    "                        data.loc[row.name, \"returns\" ] = (tp-cost) * leverage \n",
    "                        sell = False \n",
    "                        open_sell_price = None \n",
    "                        var_sell_high = 0 \n",
    "                        var_sell_low = 0 \n",
    "                        data.loc[row.name, \"duration\" ] = row.Low_time – open_sell_date \n",
    "                        open_sell_date = None \n",
    "                        \n",
    "                    elif var_sell_high < sl: \n",
    "                        data.loc[row.name, \"returns\" ] = (sl-cost) * leverage \n",
    "                        sell = False \n",
    "                        open_sell_price = None \n",
    "                        var_sell_high = 0 \n",
    "                        var_sell_low = 0 \n",
    "                        data.loc[row.name, \"duration\" ] = row.High_time – open_sell_date \n",
    "                        open_sell_date = None\n",
    "\n",
    "    # Put 0 when we have missing values\n",
    "    data[ \"returns\" ] = data[ \"returns\" ].fillna(value= 0 )\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fb4266",
   "metadata": {},
   "source": [
    "def\n",
    "monte_carlo\n",
    "(\n",
    "data\n",
    ",\n",
    "method\n",
    "=\n",
    "\"simple\"\n",
    "):\n",
    "1\n",
    "random_returns = []\n",
    "data[\n",
    "\"returns\"\n",
    "] = data[\n",
    "\"returns\"\n",
    "].fillna(value=\n",
    "0\n",
    ")\n",
    "for\n",
    "_\n",
    "in\n",
    "tqdm(\n",
    "range\n",
    "(\n",
    "100\n",
    ")):\n",
    "returns = data[\n",
    "\"returns\"\n",
    "]\n",
    "-10\n",
    "**\n",
    "-100\n",
    "2\n",
    "np.random.shuffle(returns)\n",
    "random_returns.append(returns)\n",
    "if\n",
    "method==\n",
    "\"simple\"\n",
    ":\n",
    "df_ret =\n",
    "pd.DataFrame(random_returns).transpose().cumsum()*\n",
    "100\n",
    "cur_ret = data[\n",
    "\"returns\"\n",
    "].cumsum()*\n",
    "100\n",
    "else\n",
    ":\n",
    "df_ret = ((\n",
    "1\n",
    "+pd.DataFrame(random_returns).transpose()).cumprod()\n",
    "-1\n",
    ")*\n",
    "100\n",
    "cur_ret = ((\n",
    "1\n",
    "+data[\n",
    "\"returns\"\n",
    "]).cumprod()\n",
    "-1\n",
    ")*\n",
    "100\n",
    "p_90 = np.percentile(df_ret,\n",
    "99\n",
    ", axis=\n",
    "1\n",
    ")\n",
    "p_50 = np.percentile(df_ret,\n",
    "50\n",
    ", axis=\n",
    "1\n",
    ")\n",
    "p_10 = np.percentile(df_ret,\n",
    "1\n",
    ", axis=\n",
    "1\n",
    ")\n",
    "plt.figure(figsize=(\n",
    "20\n",
    ",\n",
    "8\n",
    "))\n",
    "plt.plot(df_ret.index, p_90, color=\n",
    "\"#39B3C7\"\n",
    ")\n",
    "plt.plot(df_ret.index, p_50, color=\n",
    "\"#39B3C7\"\n",
    ")\n",
    "plt.plot(df_ret.index, p_10, color=\n",
    "\"#39B3C7\"\n",
    ")\n",
    "plt.plot(cur_ret, color=\n",
    "\"blue\"\n",
    ", alpha=\n",
    "0.60\n",
    ", linewidth=\n",
    "3\n",
    ",\n",
    "label=\n",
    "\"Current returns\"\n",
    ")\n",
    "plt.fill_between(df_ret.index, p_90, p_10,\n",
    "p_90>p_10, color=\n",
    "\"#669FEE\"\n",
    ", alpha=\n",
    "0.20\n",
    ",\n",
    "label=\n",
    "\"Monte carlo area\"\n",
    ")\n",
    "plt.ylabel(\n",
    "\"Cumulative returns %\"\n",
    ", size=\n",
    "13\n",
    ")\n",
    "plt.title(\n",
    "\"MONTE CARLO SIMULATION\"\n",
    ", size=\n",
    "20\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19fafec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus\n",
    "def profitable_month_return ( p ): \n",
    "    total = 0 positif = 0 \n",
    "    \n",
    "    r=[]\n",
    "\n",
    "    # Loop on each different year\n",
    "    for year in p.index.strftime( \"%y\" ).unique(): \n",
    "        e = [] \n",
    "        nbm = p.loc[p.index.strftime( \"%y\" )==year].index.strftime( \"%m\" ).unique()\n",
    "\n",
    "        # Loop on each different month\n",
    "        for mois in nbm: \n",
    "            monthly_values = p.loc[p.index.strftime( \"%y:%m\" )== f \" {year} : {mois} \" ] \n",
    "            sum_ = monthly_values.sum()\n",
    "\n",
    "        # Verifying that there is at least 75% of the values\n",
    "        if len(monthly_values) > 15 :\n",
    "\n",
    "            # Computing sum return\n",
    "            s = monthly_values.sum() \n",
    "            \n",
    "            if s > 0: \n",
    "                positif += 1 \n",
    "                \n",
    "            else: \n",
    "                pass \n",
    "            \n",
    "            total += 1 \n",
    "            \n",
    "        else: \n",
    "            pass \n",
    "        \n",
    "        e.append(sum_) \n",
    "        r.append(e) \n",
    "        r[0] = [ 0 for _ in range ( 12 - len (r[ 0 ]))] + r[ 0 ] r[ -1 ]= r[ -1 ] + [ 0 for _ in range ( 12 - len (r[ -1 ]))] \n",
    "        \n",
    "        return pd.DataFrame(r, columns=[ \n",
    "            \"January\" , \n",
    "            \"February\" , \n",
    "            \"March\" , \n",
    "            \"April\" , \n",
    "            \"May\" , \n",
    "            \"June\" , \n",
    "            \"July\" , \n",
    "            \"August\" , \n",
    "            \"September\" , \n",
    "            \"October\" , \n",
    "            \"November\" , \n",
    "            \"December\" \n",
    "        ], index=p.index.strftime( \"%y\" ).unique()) \n",
    "    \n",
    "    def heatmap(data): \n",
    "        htm = profitable_month_return(data[ \"returns\" ])* 100 \n",
    "        htm.index.name = \"Year\" \n",
    "        htm.index = [ f \"20 {idx} \" for idx in htm.index] \n",
    "        \n",
    "        plt.figure(figsize=( 20 , 8 )) \n",
    "        pal = sns.color_palette( \"RdYlGn\" ,n_colors= 15 ) \n",
    "        sns.heatmap(htm, annot= True , cmap =pal, vmin= -100 , vmax= 100 ) \n",
    "        \n",
    "        plt.title(\"Heatmap Monthly returns\") \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577a37e0",
   "metadata": {},
   "source": [
    "1. Time underwater\n",
    ": the percentage of time we have a drawdown\n",
    "below 0. It allows us to understand the percentage of time we will\n",
    "earn money. It is essential to understand that the time does not\n",
    "give the intensity of the loss: we can have a 1% time underwater\n",
    "and a max drawdown of 100%, so we will lose all of our capital.\n",
    "This metric should always be combined to the maximum\n",
    "drawdown.\n",
    "2. Trade lifetime\n",
    ": the average time of a trade position. The more\n",
    "scalping-like the strategy, the more the trade lifetime is essential.\n",
    "3. Assets under management\n",
    ": It is the dollar value of our portfolio\n",
    "at each time (it is a vector). We usually compute the average AUM\n",
    "(assets under management).\n",
    "4. Long – short ratio\n",
    ": Number of long positions over the number of\n",
    "sell positions. So, if we work with a long-short strategy, the more\n",
    "the value is close to 0.5, the better it is.\n",
    "5. Number of trades\n",
    ": very important to understand how many\n",
    "trades you take and see if it is accorded to your trading plan: a\n",
    "strategy with 12 trades over a year is not a significative backtest\n",
    "but 500 is.\n",
    "6. Annualized returns\n",
    ": It is essential to compute the annualized\n",
    "return to be able to compare several strategies between them.\n",
    "7. Correlation to underlying:\n",
    "Pearson’s correlation is usually\n",
    "between the strategy returns and the underlying returns. The more\n",
    "the value is close to 1, the more the strategy long the asset and the\n",
    "more the correlation is close to -1, the more the strategy short the\n",
    "asset. So, the strategy is not adding a lot of value if the correlation\n",
    "is close to -1 or 1.\n",
    "8. HIT ratio:\n",
    "percentage of winning trade. It must be associated\n",
    "with the risk-reward ratio.\n",
    "9. Risk-reward ratio:\n",
    "Essential to understand how many our risk is\n",
    "compared to our targeted reward. Again, HIT and risk-reward\n",
    "ratios (R ratios) are the two faces of the same coin\n",
    "10. Sharpe ratio:\n",
    "An essential financial metric, it allows us to\n",
    "understand the benefits of return of one more percentage risk. It\n",
    "must be annualized.\n",
    "11. Sortino ratio:\n",
    "Same metric as the Sharpe ratio, but we compute\n",
    "the risk using the downward volatility instead of the classic\n",
    "volatility for the Sharpe ratio.\n",
    "12. Beta:\n",
    "It will give us some indications about how much the\n",
    "strategy is correlated to the market (SP500, for example) (more\n",
    "explanation in chapter 5)\n",
    "13. Alpha:\n",
    "tells us how the strategy overperforms or underperforms\n",
    "the market. (More explanation in chapter 5)\n",
    "14. Information ratio:\n",
    "it will allow us to compare the risk-reward\n",
    "couple of the strategy to the benchmark risk-reward couple.\n",
    "15. Risk-free asset return:\n",
    "Consider the risk-free asset returns over\n",
    "the period (annualized) to compare them to the annualized\n",
    "strategy returns.\n",
    "16. VaR:\n",
    "Will give us the worst loss we can make with a 5% error\n",
    "threshold. We can compute it on the period that you want: the\n",
    "worst loss per day, month or year for example. (More explanation\n",
    "in chapter 5)\n",
    "17. cVaR:\n",
    "Like the VaR but some difference in the computation.\n",
    "(More explanation in chapter 5)\n",
    "\n",
    "\n",
    "Use 20 backtest metrics will not render your strategy\n",
    "better. In my opinion, 5 good indicators are clearly\n",
    "enough to have a quick overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bf4468",
   "metadata": {},
   "source": [
    "So far, we have analyzed the performance of our strategy on only one\n",
    "possible path. Indeed, the past is only one possible path between an\n",
    "infinity.\n",
    "To analyze different possible paths, we can use Monte Carlo\n",
    "simulations. To create one Monte-Carlo simulation, we will randomly\n",
    "take the strategy returns and reorganize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0560f014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo ( data , method = \"simple\" ):\n",
    "    random_returns = [] \n",
    "    data[ \"returns\" ] = data[ \"returns\" ].fillna(value= 0 ) \n",
    "    \n",
    "    for _ in tqdm( range ( 100 )): \n",
    "        returns = data[ \"returns\" ] -10 * -100\n",
    "        np.random.shuffle(returns) \n",
    "        random_returns.append(returns) \n",
    "        \n",
    "    if method== \"simple\" : \n",
    "        df_ret = pd.DataFrame(random_returns).transpose().cumsum() * 100 \n",
    "        cur_ret = data[ \"returns\" ].cumsum() * 100 \n",
    "    else : \n",
    "        df_ret = (( 1 +pd.DataFrame(random_returns).transpose()).cumprod() -1 ) * 100 \n",
    "        cur_ret = (( 1 +data[ \"returns\" ]).cumprod() -1 )* 100 \n",
    "        \n",
    "    p_90 = np.percentile(df_ret, 99 , axis= 1 ) \n",
    "    p_50 = np.percentile(df_ret, 50 , axis= 1 ) \n",
    "    p_10 = np.percentile(df_ret, 1 , axis= 1 ) \n",
    "    plt.figure(figsize=( 20 , 8 )) \n",
    "    plt.plot(df_ret.index, p_90, color= \"#39B3C7\" ) \n",
    "    plt.plot(df_ret.index, p_50, color= \"#39B3C7\" ) \n",
    "    plt.plot(df_ret.index, p_10, color= \"#39B3C7\" ) \n",
    "    plt.plot(cur_ret, color= \"blue\" , alpha= 0.60 , linewidth= 3 , label= \"Current returns\" ) \n",
    "    plt.fill_between(df_ret.index, p_90, p_10, p_90 > p_10, color= \"#669FEE\" , alpha= 0.20 , label= \"Monte carlo area\" ) \n",
    "    plt.ylabel( \"Cumulative returns %\" , size= 13 ) \n",
    "    plt.title( \"MONTE CARLO SIMULATION\" , size= 20 )\n",
    "    plt.legend() \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f93e304",
   "metadata": {},
   "source": [
    "def\n",
    "run_tsl\n",
    "(\n",
    "data\n",
    ",\n",
    "leverage\n",
    "=\n",
    "1\n",
    ",\n",
    "tp\n",
    "=\n",
    "0.015\n",
    ",\n",
    "sl\n",
    "=\n",
    "-0.015\n",
    ",\n",
    "tsl\n",
    "=\n",
    "0.001\n",
    ",\n",
    "cost\n",
    "=\n",
    "0.00\n",
    "):\n",
    "\"\"\"\n",
    ":params (mandatory): data(have to contain a High_time and a Low_time\n",
    "columns)\n",
    ":params (optional): leverage=1, tp=0.015, sl=-0.015, cost=0.00\n",
    ":return: data with three new columns: Low_time (TimeStamp),\n",
    "High_time (TimeStamp), High_first (Boolean)\n",
    "\"\"\"\n",
    "tpl = tp – tsl\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa06e58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tsl(data, leverage=1, tp=0.015, sl=-0.015, tsl=0.001, cost=0.00): \n",
    "    \"\"\" \n",
    "        :params (mandatory): data(have to contain a High_time and a Low_time columns) \n",
    "        :params (optional): leverage=1, tp=0.015, sl=-0.015, cost=0.00 :return: data with three new columns: Low_time (TimeStamp), High_time (TimeStamp), High_first (Boolean) \n",
    "    \"\"\" \n",
    "    tpl = tp – tsl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
